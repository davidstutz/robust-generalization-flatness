{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICCV Evaluation and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "sys.path.insert(1, os.path.dirname(os.path.abspath('')) + '/../../')\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import common.experiments.eval as ev \n",
    "import experiments.iccv.cifar10_noaa as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import datetime\n",
    "import terminaltables\n",
    "import common.summary\n",
    "import common.numpy\n",
    "import common.plot\n",
    "import common.utils\n",
    "from common.log import log, LogLevel\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-bright')\n",
    "matplotlib.rcParams['figure.dpi'] = 125\n",
    "matplotlib.rcParams['axes.grid'] = True\n",
    "matplotlib.rcParams['axes.titlesize'] = 15\n",
    "matplotlib.rcParams['legend.fontsize'] = 12\n",
    "matplotlib.rcParams['xtick.labelsize'] = 11\n",
    "matplotlib.rcParams['ytick.labelsize'] = 11\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['legend.framealpha'] = 0.5\n",
    "matplotlib.rcParams['legend.edgecolor'] = 'inherit'\n",
    "matplotlib.rcParams['legend.facecolor'] = 'white'\n",
    "matplotlib.rcParams['legend.frameon'] = True\n",
    "matplotlib.rcParams['legend.fancybox'] = False\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.2\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4\n",
    "matplotlib.rcParams['legend.handlelength'] = 1.5\n",
    "matplotlib.rcParams['legend.handleheight'] = 0.5\n",
    "matplotlib.rcParams['lines.linewidth'] = 3\n",
    "matplotlib.rcParams['lines.markersize'] = 6.5\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_models(subset='', short=True):\n",
    "    \"\"\"\n",
    "    Contains and provides a list of all models or models used for specific experiments.\n",
    "    \n",
    "    :param subset: experiment subset\n",
    "    :type subset: str\n",
    "    :param short: whether to return short names of models\n",
    "    :type short: bool\n",
    "    :return: model config variable names, training suffixes and model labels/names\n",
    "    :rtype: [str], [str], [str]\n",
    "    \"\"\"\n",
    "    models = [\n",
    "        [['corr-method-main', 'corr'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', 'AT (baseline)'], #\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i14_e00314_f100', 'PGD-14'], #\n",
    "        #\n",
    "        [['corr'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00352_f100', r\"Larger $\\epsilon{=}9/255$\"], #\n",
    "        # ii\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_ii_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', 'Ignore incorrect'], #\n",
    "        # pll\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_pll_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', 'Prevent label leaking'],\n",
    "        # weight clipping\n",
    "        [['corr'], '_resnet18_rebn_whiten_64', '0005p_at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', 'Weight clipping $w_{max}{=}0.005$', 'Weight clipping'], #\n",
    "        # label smoothing\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ls01', r\"Label smoothing $\\tau{=}0.1$\", 'Label smoothing'], #\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ls02', r\"Label smoothing $\\tau{=}0.2$\", 'Label smoothing'], #\n",
    "        [['corr'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ls03', r\"Label smoothing $\\tau{=}0.3$\", 'Label smoothing'], #\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ls04', r\"Label smoothing $\\tau{=}0.4$\", 'Label smoothing'], #\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ls05', r\"Label smoothing $\\tau{=}0.5$\", 'Label smoothing'], #\n",
    "        # label noise\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ln01', r\"Label noise $\\tau{=}0.1$\", 'Label noise'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ln02', r\"Label noise $\\tau{=}0.2$\", 'Label noise'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ln03', r\"Label noise $\\tau{=}0.3$\", 'Label noise'], #\n",
    "        [['corr-method-main', 'corr'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ln04', r\"Label noise $\\tau{=}0.4$\", 'Label noise'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_ln05', r\"Label noise $\\tau{=}0.5$\", 'Label noise'], #\n",
    "        # cyc\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_cyc', 'Cyclic', 'Cyclic'],\n",
    "        # weight decay\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_wd0001', 'Weight decay $0.001$', 'Weight decay'], #\n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_wd001', 'Weight decay $0.01$', 'Weight decay'], #\n",
    "        [['corr'], '_resnet18_rebn_whiten_64', 'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100_wd005', 'Weight decay $0.05$', 'Weight decay'], #\n",
    "        # ssl \n",
    "        [['corr-other'], '_resnet18_rebn_whiten_64', 'at_ssl05_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"Self-supervision $\\lambda{=}0.5$\", 'Self-supervision'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_ssl1_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"Self-supervision $\\lambda{=}1$\", 'Self-supervision'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_ssl2_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"Self-supervision $\\lambda{=}2$\", 'Self-supervision'], #\n",
    "        [['corr-method-main', 'corr'], '_resnet18_rebn_whiten_64', 'at_ssl4_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"Self-supervision $\\lambda{=}4$\", 'Self-supervision'], #\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'at_ssl8_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"Self-supervision $\\lambda{=}8$\", 'Self-supervision'], #\n",
    "        # trades\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'trades1_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"TRADES $\\lambda{=}1$\", 'TRADES'],\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'trades3_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"TRADES $\\lambda{=}3$\", 'TRADES'],\n",
    "        [['corr-method-main', 'corr-other'], '_resnet18_rebn_whiten_64', 'trades6_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"TRADES $\\lambda{=}6$\", 'TRADES'],\n",
    "        [['corr-method-main', 'corr'], '_resnet18_rebn_whiten_64', 'trades9_linf_gd_normalized_lr0007_mom0_i7_e00314_f100', r\"TRADES $\\lambda{=}9$\", 'TRADES'],\n",
    "    ]\n",
    "    \n",
    "    training_config_vars = []\n",
    "    training_suffixes = []\n",
    "    training_labels = []\n",
    "    for model in models:\n",
    "        if subset == '' or subset in model[0]:\n",
    "            training_label = model[4] if short and len(model) > 4 else model[3]\n",
    "             \n",
    "            training_suffixes.append(model[1])\n",
    "            training_config_vars.append(model[2])\n",
    "            training_labels.append(training_label)\n",
    "    \n",
    "    assert len(training_labels) == len(training_config_vars)\n",
    "    assert len(training_suffixes) == len(training_config_vars)\n",
    "    return training_config_vars, training_suffixes, training_labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Requires actually training the vanilla adversarial training model to generate the logs used for plotting!**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def iccv_plot_training_single(\n",
    "    config, training_config, tags, factors=None, labels=None, index=-1, reference=None,\n",
    "    xmin=None, xmax=None, ymin=None, ymax=None, w=None, h=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot training (robust) loss throughout training from logs. Assumes that for training a PickleSummaryWriter was used.\n",
    "    \"\"\"\n",
    "    \n",
    "    log_dir = ev.get_log_directory(config, training_config)\n",
    "    log_dir += '/logs'\n",
    "    logs = os.listdir(log_dir)\n",
    "    logs.sort(key=lambda date: datetime.datetime.strptime(date, \"%d%m%y%H%M%S\"))\n",
    "    \n",
    "    # Comment out if you started training a couple of times and have multiple logs:\n",
    "    # for log in logs:\n",
    "    #     print('%s: %s.%s.%s %s:%s:%s' % (\n",
    "    #         log,\n",
    "    #         log[0:2],\n",
    "    #         log[2:4],\n",
    "    #         log[4:6],\n",
    "    #         log[6:8],\n",
    "    #         log[8:10],\n",
    "    #         log[10:12],\n",
    "    #     ))\n",
    "    \n",
    "    log_sub_dir = log_dir + '/' + logs[index]\n",
    "    summary_reader = common.summary.SummaryPickleReader(log_sub_dir)\n",
    "\n",
    "    for tag in tags:\n",
    "        assert tag in summary_reader.tags()\n",
    "        \n",
    "    if factors is None:\n",
    "        factors = [1]*len(tags)\n",
    "    else:\n",
    "        assert len(factors) == len(tags)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = tags\n",
    "    else:\n",
    "        assert len(labels) == len(tags)\n",
    "        \n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    max_x = 0\n",
    "    for t in range(len(tags)):\n",
    "        tag = tags[t]\n",
    "        factor = factors[t]\n",
    "        label = labels[t]\n",
    "        data = numpy.array(summary_reader.get_scalar(tag))\n",
    "        max_x = max(max_x, numpy.max(factor*data[:, 0]))\n",
    "        \n",
    "        x = data[:, 0]/numpy.max(data[:, 0])\n",
    "        y = data[:, 1]\n",
    "        \n",
    "        if reference:\n",
    "            reference_value = numpy.min(y)\n",
    "        \n",
    "        if tag.find('train') >= 0:\n",
    "            y = savgol_filter(y, 51, 1) # window size 51, polynomial order 3\n",
    "        ax.plot(x, y,\n",
    "                label=label, color=common.plot.color_brewer[t])\n",
    "        \n",
    "    if reference:\n",
    "        ax.plot(\n",
    "            numpy.array([0, 1]), numpy.array([reference_value, reference_value]),\n",
    "            color=common.plot.color_brewer[len(tags)], label='Early Stopping (ES)', linewidth=2)\n",
    "        \n",
    "    common.plot.label(\n",
    "        ax, label=True, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, w=w, h=h, legend=True, **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=[ \n",
    "        'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes='_resnet18_rebn_whiten_64',\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "index = -1\n",
    "color_brewer_ = numpy.array([\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "])\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "iccv_plot_training_single(\n",
    "    config, training_configs[0], tags=[\n",
    "        'train/adversarial_loss',\n",
    "        'test/adversarial_loss',\n",
    "        'test/adversarial_correct_loss',\n",
    "        'test/adversarial_incorrect_loss',\n",
    "    ], factors=[\n",
    "        1,\n",
    "        782, \n",
    "        782,\n",
    "        782,\n",
    "    ], labels=[\n",
    "        'Train', \n",
    "        'Test', \n",
    "        'Test (correct)',\n",
    "        'Test (incorrect)',\n",
    "    ], index=index, ymin=0, xmin=0, ymax=10.5, xmax=1, w=4, h=3,\n",
    "    legend_loc='upper left', legend_anchor=(0.01, 0.99),\n",
    "    xlabel='Epochs (Normalized)', ylabel='Robust Loss (RLoss)',\n",
    "    title=r\"\\textbf{Overfitting in Robust Loss}\")\n",
    "\n",
    "color_brewer_ = numpy.array([\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [227, 26, 28],\n",
    "])\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "iccv_plot_training_single(\n",
    "    config, training_configs[0], tags=[\n",
    "        'train/adversarial_error',\n",
    "        'test/adversarial_error',\n",
    "    ], factors=[\n",
    "        1,\n",
    "        782,\n",
    "    ], labels=[\n",
    "        'Train',\n",
    "        'Test',\n",
    "    ], index=index, reference=True,\n",
    "    ymin=0, xmin=0, ymax=0.8, xmax=1, w=4, h=3,\n",
    "    legend_loc='lower left', legend_anchor=(0.01, 0.01),\n",
    "    xlabel='Epochs (Normalized)', ylabel='Robust Error (RErr)',\n",
    "    title=r\"\\textbf{Overfitting in Robust \\emph{Error}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Hessian Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def iccv_plot_weight_1d_compare(\n",
    "    config, training_configs, attack_config, loss_attack=None, normalization='',\n",
    "    statistic='mean', clip=2.5, plot_log=False, epoch=None, adversarial=False,\n",
    "    labels=None, legend=True, errors=False, flip=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot robust loss along a random or adversarial direction according to the provided attack_config.\n",
    "    \"\"\"\n",
    "    \n",
    "    if labels is None:\n",
    "        labels =  [training_config.directory for training_config in training_configs]\n",
    "        \n",
    "    xs = None\n",
    "    ys = None\n",
    "        \n",
    "    for training_config in training_configs:\n",
    "        visualization_directory = common.paths.experiment_dir('%s/%s_%s_%svisualization' % (\n",
    "            training_config.directory, attack_config.directory,\n",
    "            normalization, 'adversarial_' if adversarial else '',\n",
    "        ))\n",
    "        if loss_attack is not None:\n",
    "            visualization_directory += '/%s' % loss_attack.directory\n",
    "        visualization_file = os.path.join(visualization_directory, 'visualization%s' % common.paths.HDF5_EXT)\n",
    "        if epoch is not None:\n",
    "            visualization_file += '.%d' % epoch\n",
    "\n",
    "        if not os.path.exists(visualization_file):\n",
    "            log('file %s not found' % visualization_file, LogLevel.ERROR)\n",
    "            continue;\n",
    "\n",
    "        steps = common.utils.read_hdf5(visualization_file, 'steps')\n",
    "        losses = common.utils.read_hdf5(visualization_file, 'losses')\n",
    "        factors = common.utils.read_hdf5(visualization_file, 'factors')\n",
    "\n",
    "        if errors:\n",
    "            losses = common.utils.read_hdf5(visualization_file, 'errors')\n",
    "        else:\n",
    "            if plot_log:\n",
    "                losses = numpy.log(1 + losses)\n",
    "            else:\n",
    "                losses = numpy.clip(losses, 0, clip)\n",
    "\n",
    "        x = getattr(numpy, statistic)(steps, axis=0)\n",
    "        y = getattr(numpy, statistic)(losses, axis=0)\n",
    "        \n",
    "        xs = common.numpy.concatenate(xs, numpy.expand_dims(x, axis=0))\n",
    "        ys = common.numpy.concatenate(ys, numpy.expand_dims(y, axis=0))\n",
    "    \n",
    "    if flip:\n",
    "        ys = numpy.flip(ys, axis=1)\n",
    "    \n",
    "    plt.clf()\n",
    "    if legend:\n",
    "        common.plot.line(\n",
    "            xs, ys, labels=labels, ax=plt.gca(), markers=['.']*xs.shape[0],\n",
    "            markersize=matplotlib.rcParams['lines.markersize'],\n",
    "            linewidth=matplotlib.rcParams['lines.linewidth'], **kwargs)\n",
    "    else:\n",
    "        common.plot.line(\n",
    "            xs, ys, labels=None, ax=plt.gca(), markers=['.']*xs.shape[0],\n",
    "            markersize=matplotlib.rcParams['lines.markersize'],\n",
    "            linewidth=matplotlib.rcParams['lines.linewidth'], **kwargs)\n",
    "        plt.gca().get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 6.5\n",
    "color_brewer_ = numpy.array([\n",
    "    [166, 206, 227],\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']*1\n",
    "training_configs, weight_attack_configs = ev.load(config,\n",
    "    training_config_vars=[\n",
    "        'at_linf_gd_normalized_lr0007_mom0_i14_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes=[\n",
    "        '_resnet18_rebn_whiten_64'\n",
    "    ],\n",
    "    attack_config_vars=[\n",
    "        'weight_l2_random_nonorm2_e01_at10'\n",
    "    ],\n",
    ")\n",
    "input_attacks_configs = ev.load_input(config, attack_config_vars=[\n",
    "    'input_linf_gd_normalized_lr0007_mom0_i10_e00314_at10',\n",
    "])\n",
    "normalization = 'layer_l2_05'\n",
    "iccv_plot_weight_1d_compare(\n",
    "    config, training_configs, weight_attack_configs[0],\n",
    "    ylabel='Average RLoss',\n",
    "    loss_attack=input_attacks_configs[0],\n",
    "    normalization=normalization, plot_log=False, clip=100, h=2.5, w=4,\n",
    "    legend_loc='upper right', legend_anchor=(-0.125, 1.015),\n",
    "    adversarial=True, xmin=-1.025, xmax=1.025, ymin=0.75, ymax=15,\n",
    "    title=r\"\\textbf{Random Directions}\", save='main_random', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_brewer_ = numpy.array([\n",
    "    [166, 206, 227],\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']*1\n",
    "training_configs, weight_attack_configs = ev.load(config,\n",
    "    training_config_vars=[\n",
    "        'at_linf_gd_normalized_lr0007_mom0_i14_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes=[\n",
    "        '_resnet18_rebn_whiten_64'\n",
    "    ],\n",
    "    attack_config_vars=[\n",
    "        'weight_l2_gd_nonorm2_lwrl2normalized_i7_lr001_mom0_e0005_at10_test'\n",
    "    ],\n",
    ")\n",
    "input_attacks_configs = ev.load_input(config, attack_config_vars=[\n",
    "    'input_linf_gd_normalized_lr0007_mom0_i10_e00314_at10',\n",
    "])\n",
    "normalization = 'layer_l2_001'\n",
    "iccv_plot_weight_1d_compare(\n",
    "    config, training_configs, weight_attack_configs[0],\n",
    "    ylabel='Worst RLoss',\n",
    "    loss_attack=input_attacks_configs[0],\n",
    "    normalization=normalization, plot_log=False, clip=100, h=2.5, w=2.5,\n",
    "    legend_loc='upper left', legend_anchor=(0.01, 0.99),\n",
    "    adversarial=True, xmin=0, xmax=1, ymin=0.75, ymax=15,\n",
    "    title=r\"\\textbf{Adversarial Directions}\",\n",
    "    save='main_adversarial', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def iccv_get_hessian_table(\n",
    "    config, training_configs, k, test_input_evaluations,\n",
    "    train_input_evaluations, training_labels=None):\n",
    "    \"\"\"\n",
    "    Print Table of test and train robustness and Hessian eigenvalues.\n",
    "    \"\"\"\n",
    "    \n",
    "    table_data = []\n",
    "    if training_labels is not None:\n",
    "        assert len(training_labels) == len(training_configs)\n",
    "\n",
    "    table_data.append([\n",
    "        '**Model**',\n",
    "        '**Test**',\n",
    "        '**Train**',\n",
    "        '**MAX**',\n",
    "        '**abs(MIN)/MAX**',\n",
    "    ])\n",
    "    \n",
    "    if training_labels is None:\n",
    "        training_labels = [training_configs[t].directory for t in range(len(training_configs))]\n",
    "\n",
    "    for t in range(len(training_configs)):\n",
    "        training_config = training_configs[t]\n",
    "        eigs_file = common.paths.experiment_file(\n",
    "            training_config.directory, 'eigenvalues_%d' % k, common.paths.PICKLE_EXT)\n",
    "        eigs = common.utils.read_pickle(eigs_file)\n",
    "\n",
    "        test_rte = 0\n",
    "        train_rte = 0\n",
    "        if test_input_evaluations[t][0] is not None:\n",
    "            test_rte = round(test_input_evaluations[t][0].robust_test_error(), 4)*100\n",
    "        if train_input_evaluations[t][0] is not None:\n",
    "            train_rte = round(train_input_evaluations[t][0].robust_test_error(), 4)*100\n",
    "        diff_rte = test_rte - train_rte\n",
    "        table_data.append([\n",
    "            training_labels[t],\n",
    "            '%.1f' % test_rte,\n",
    "            '%g (%g)' % (train_rte, diff_rte),\n",
    "            '%g' % eigs[-1],\n",
    "            '%.3f' % (abs(eigs[0])/eigs[-1]),\n",
    "        ])\n",
    "\n",
    "    table = terminaltables.GithubFlavoredMarkdownTable(table_data)\n",
    "    \n",
    "    return table.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=[\n",
    "        'at_linf_gd_normalized_lr0007_mom0_i14_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes=[\n",
    "        '_resnet18_rebn_whiten_64'\n",
    "    ],\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_attacks_configs = ev.load_input(config, attack_config_vars=[\n",
    "    'input_linf_aa_standard_e00314',\n",
    "])\n",
    "input_evaluations, input_epochs = ev.get_input_attack_evaluations(\n",
    "    config, training_configs, input_attacks_configs, limit=10000)\n",
    "train_input_attacks_configs = ev.load_input(config, attack_config_vars=[\n",
    "    'input_linf_aa_standard_e00314_train',\n",
    "])\n",
    "train_input_evaluations, train_input_epochs = ev.get_input_attack_evaluations(\n",
    "    config, training_configs, train_input_attacks_configs, limit=10000, train=True)\n",
    "display(Markdown(iccv_get_hessian_table(\n",
    "    config, training_configs, 4, input_evaluations, train_input_evaluations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Loss vs. Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def iccv_loss_err(\n",
    "    config, training_configs, input_evaluations, aa_input_evaluations,\n",
    "    legend_ncol=1, labels=None, legend=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot robust error against robust loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(aa_input_evaluations) == len(input_evaluations)\n",
    "    assert len(input_evaluations[0]) == 1\n",
    "    assert len(aa_input_evaluations[0]) == 1\n",
    "    \n",
    "    x = []\n",
    "    y = [] \n",
    "    c = []\n",
    "    clean_labels = []\n",
    "    \n",
    "    if labels is not None:\n",
    "        set_labels = False \n",
    "    else: \n",
    "        set_labels = True\n",
    "        \n",
    "    c_ = 0\n",
    "    mapping = dict()\n",
    "    for t in range(len(training_configs)):\n",
    "        if input_evaluations[t][0] is not None and aa_input_evaluations[t][0] is not None:\n",
    "            y.append(round(getattr(aa_input_evaluations[t][0], 'robust_test_error')(), 4)*100)\n",
    "            x.append(round(getattr(input_evaluations[t][0], 'robust_loss')(), 2))\n",
    "            \n",
    "            if labels is None:\n",
    "                clean_labels.append(training_configs[t].directory)\n",
    "                c.append(c_)\n",
    "                c_ += 1\n",
    "            else:\n",
    "                if labels[t] not in mapping.keys():\n",
    "                    c.append(c_)\n",
    "                    mapping[labels[t]] = c_\n",
    "                    c_ += 1\n",
    "                    clean_labels.append(labels[t])\n",
    "                else:\n",
    "                    c.append(mapping[labels[t]])\n",
    "    \n",
    "    x = numpy.array(x)\n",
    "    y = numpy.array(y)\n",
    "    c = numpy.array(c)\n",
    "    \n",
    "    plt.clf()\n",
    "    common.plot.scatter(\n",
    "        x, y, c=c, labels=clean_labels,\n",
    "        s=matplotlib.rcParams['lines.markersize'], **kwargs, ax=plt.gca())\n",
    "    legend_ = plt.gca().legend(\n",
    "        ncol=legend_ncol, loc=kwargs.get('legend_loc', None),\n",
    "        bbox_to_anchor=kwargs.get('legend_anchor', None))\n",
    "    legend_.get_frame().set_alpha(None)\n",
    "    legend_.get_frame().set_facecolor((1, 1, 1, 0.5))\n",
    "    \n",
    "    x1 = x[x < 2.3]\n",
    "    y1 = y[x < 2.3]\n",
    "    x2 = x[x >= 2.3]\n",
    "    y2 = y[x >= 2.3]\n",
    "        \n",
    "    res1 = stats.linregress(x1, y1)\n",
    "    res2 = stats.linregress(x2, y2)\n",
    "    xs1 = numpy.array([numpy.min(x1), numpy.max(x1)])\n",
    "    plt.gca().plot(\n",
    "        xs1, res1.intercept + res1.slope*xs1,\n",
    "        color='red', marker=None, linewidth=3, linestyle=':')\n",
    "    xs2 = numpy.array([numpy.min(x2), numpy.max(x2)])\n",
    "    plt.gca().plot(\n",
    "        xs2, res2.intercept + res2.slope*xs2,\n",
    "        color='red', marker=None, linewidth=3, linestyle=':')\n",
    "    \n",
    "    if not legend:\n",
    "        plt.gca().get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 100\n",
    "color_brewer_ = numpy.array([\n",
    "    [155, 155, 155],\n",
    "    #\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "    [51, 160, 44],\n",
    "    [227, 26, 28],\n",
    "    [253, 191, 111],\n",
    "    [255, 127, 0],\n",
    "\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']\n",
    "common.plot.marker_brewer += ['o']*8\n",
    "\n",
    "training_config_vars1, training_suffixes1, _ = get_models('corr-other')\n",
    "training_config_vars2, training_suffixes2, training_labels2 = get_models('corr')\n",
    "assert common.plot.color_brewer.shape[0] == len(training_config_vars2) + 1, common.plot.color_brewer.shape[0]\n",
    "assert len(common.plot.marker_brewer) == len(training_config_vars2) + 1, len(common.plot.marker_brewer)\n",
    "\n",
    "training_config_vars = training_config_vars1 + training_config_vars2\n",
    "training_suffixes = training_suffixes1 + training_suffixes2\n",
    "training_labels = ['Other']*len(training_config_vars1) + training_labels2\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=training_config_vars,\n",
    "    training_suffixes=training_suffixes,\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_attack_configs = ev.load_input(\n",
    "    config, attack_config_vars=[\n",
    "        [\n",
    "            'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "        ],\n",
    "        [\n",
    "            'input_linf_aa_standard_e00314',\n",
    "        ],\n",
    "    ])\n",
    "input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "    config, training_configs, [input_attack_configs[0]], validation=0, train=False)\n",
    "aa_input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "    config, training_configs, [input_attack_configs[1]], validation=0, train=False)\n",
    "iccv_loss_err(\n",
    "    config, training_configs, input_evaluations, aa_input_evaluations,\n",
    "    save='main_loss_error', legend_ncol=1, labels=training_labels, legend=True,\n",
    "    legend_loc='upper right', legend_anchor=(-0.15, 1.075), h=5.3, w=5.3,\n",
    "    title=r\"\\textbf{\\emph{RErr} vs. RLoss}\",\n",
    "    ylabel='RErr (AutoAttack)', xlabel='RLoss (PGD)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Flatness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Flatness throughout Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iccv_plot_flatness_epochs(\n",
    "    config, training_config, weight_input_evaluations1, weight_input_evaluations2,\n",
    "    input_evaluations, train_input_evaluations, k=10, epochs=list(range(0, 150, 10)) + [None], **kwargs):\n",
    "    \"\"\"\n",
    "    Plot robust loss and flatness over epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(weight_input_evaluations1) == len(epochs)\n",
    "    assert len(weight_input_evaluations2) == len(epochs)\n",
    "    assert len(input_evaluations) == len(epochs)\n",
    "    \n",
    "    eigs = None\n",
    "    x = []\n",
    "    y4 = []\n",
    "    y5 = []\n",
    "    y7 = []\n",
    "    for e in range(len(epochs)):\n",
    "        epoch = epochs[e]\n",
    "        factor = 1\n",
    "        if weight_input_evaluations1[e][0] is not None:\n",
    "            y4.append(round(weight_input_evaluations1[e][0]('robust_loss', 'mean')[0], 4)*factor -\\\n",
    "                     round(input_evaluations[e][0].robust_loss(), 4)*factor)\n",
    "        if weight_input_evaluations2[e][0] is not None:\n",
    "            y5.append(round(weight_input_evaluations2[e][0]('robust_loss', 'max')[0], 4)*factor -\\\n",
    "                     round(input_evaluations[e][0].robust_loss(), 4)*factor)\n",
    "        if input_evaluations[e][0] is not None:\n",
    "            y7.append(round(input_evaluations[e][0].robust_loss(), 4)*factor)\n",
    "        x.append((epoch if epoch is not None else 150)/150.)\n",
    "    \n",
    "    y4 = numpy.array(y4)\n",
    "    y5 = numpy.array(y5)\n",
    "    y7 = numpy.array(y7)\n",
    "    x = numpy.array(x)\n",
    "    \n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.plot(x, y7, label='Test RLoss', color=common.plot.color_brewer[1])\n",
    "    ax.plot(x, y4, label=r\"Avg flatness RLoss\",\n",
    "            color=common.plot.color_brewer[5])\n",
    "    ax.plot(x, y5, label=r\"Worst flatness RLoss\",\n",
    "            color=common.plot.color_brewer[6])\n",
    "    \n",
    "    ax.vlines([0.4], 0, 4, color='black', linewidth=2, linestyle=':', label='Early Stopping')\n",
    "    \n",
    "    legend_ = ax.legend(loc=kwargs.get('legend_loc', None), bbox_to_anchor=kwargs.get('legend_anchor', None))\n",
    "    legend_.get_frame().set_alpha(None)\n",
    "    legend_.get_frame().set_facecolor((1, 1, 1, 0.5))\n",
    "    common.plot.label(ax, **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_brewer_ = numpy.array([\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "    [51, 160, 44],\n",
    "    [227, 26, 28],\n",
    "    [253, 191, 111],\n",
    "\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']*6\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=[\n",
    "        'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes='_resnet18_rebn_whiten_64',\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_attack_configs = ev.load_input(\n",
    "    config, attack_config_vars=[\n",
    "        [\n",
    "            'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "        ],\n",
    "    ])\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "        ['sequential2_weight_input_l2_random_nonorm2_e05_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "        ['joint_weight_input_l2_gd_nonorm2_lwrl2normalized_lr001_e000075_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "    ])\n",
    "\n",
    "input_evaluations = []\n",
    "weight_input_evaluations1 = []\n",
    "weight_input_evaluations2 = []\n",
    "weight_input_evaluations3 = []\n",
    "epochs = list(range(5, 150, 10)) + [None]\n",
    "for epoch in epochs:\n",
    "    input_evaluation, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attack_configs[0]], validation=0, train=False, epoch=epoch)\n",
    "    weight_input_evaluation1, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[0]], train=False, epoch=epoch)\n",
    "    weight_input_evaluation2, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[1]], train=False, epoch=epoch)\n",
    "    input_evaluations.append(input_evaluation[0]) \n",
    "    weight_input_evaluations1.append(weight_input_evaluation1[0])\n",
    "    weight_input_evaluations2.append(weight_input_evaluation2[0])\n",
    "\n",
    "iccv_plot_flatness_epochs(\n",
    "    config, training_configs[0], weight_input_evaluations1, weight_input_evaluations2,\n",
    "    input_evaluations, train_input_evaluations, k=2, save='main_flatness_epochs',\n",
    "    xmin=0, xmax=1, ymin=0, ymax=4, h=3.5, w=5,\n",
    "    legend_loc='upper left', legend_anchor=(0, 1),\n",
    "    ylabel='RLoss / Flatness', xlabel='Epoch (Normalized)',\n",
    "    title=r\"\\textbf{Flatness Throughout Training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iccv_plot_weight_input_correlation2(\n",
    "    config, training_configs, weight_evaluations, input_evaluations,\n",
    "    weight_metric='robust_test_error',  weight_statistic='max', weight_factor=100,\n",
    "    input_metric='robust_test_error', reference_input_metric='robust_test_error',\n",
    "    input_factor=100, legend_ncol=1, labels=None, legend=True, zero_x=False, regression=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot correlation between robust loss and flatness.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(weight_evaluations) > 0\n",
    "    assert len(weight_evaluations) == len(input_evaluations)\n",
    "    assert len(weight_evaluations[0]) == 1\n",
    "    assert len(input_evaluations[0]) == 1\n",
    "    \n",
    "    x = []\n",
    "    y = [] \n",
    "    c = []\n",
    "    clean_labels = []\n",
    "    \n",
    "    if labels is not None:\n",
    "        set_labels = False \n",
    "    else: \n",
    "        set_labels = True\n",
    "        \n",
    "    c_ = 0\n",
    "    mapping = dict()\n",
    "    for t in range(len(training_configs)):\n",
    "        if weight_evaluations[t][0] is not None and input_evaluations[t][0] is not None:\n",
    "            x.append(round(weight_evaluations[t][0](weight_metric, weight_statistic)[0], 4)*weight_factor -\\\n",
    "                     round(getattr(input_evaluations[t][0], reference_input_metric)(), 4)*input_factor)\n",
    "            y.append(round(getattr(input_evaluations[t][0], input_metric)(), 4)*input_factor)\n",
    "            \n",
    "            if labels is None:\n",
    "                clean_labels.append(training_configs[t].directory)\n",
    "                c.append(c_)\n",
    "                c_ += 1\n",
    "            else:\n",
    "                if labels[t] not in mapping.keys():\n",
    "                    c.append(c_)\n",
    "                    mapping[labels[t]] = c_\n",
    "                    c_ += 1\n",
    "                    clean_labels.append(labels[t])\n",
    "                else:\n",
    "                    c.append(mapping[labels[t]])\n",
    "    \n",
    "    x = numpy.array(x)\n",
    "    if zero_x:\n",
    "        x = numpy.maximum(numpy.zeros(x.shape), x)\n",
    "    y = numpy.array(y)\n",
    "    c = numpy.array(c)\n",
    "    \n",
    "    plt.clf()\n",
    "    if regression:\n",
    "        res = stats.linregress(x, y)\n",
    "        xs1 = numpy.array([numpy.min(x), numpy.max(x)])\n",
    "        plt.gca().plot(xs1, res.intercept + res.slope*xs1,\n",
    "                       color='red', marker=None, linewidth=3, linestyle=':')\n",
    "        \n",
    "    common.plot.scatter(x, y, c=c, labels=clean_labels,\n",
    "                        s=matplotlib.rcParams['lines.markersize'], **kwargs, ax=plt.gca())\n",
    "    legend_ = plt.gca().legend(ncol=legend_ncol, loc=kwargs.get('legend_loc', None), bbox_to_anchor=kwargs.get('legend_anchor', None))\n",
    "    legend_.get_frame().set_alpha(None)\n",
    "    legend_.get_frame().set_facecolor((1, 1, 1, 0.5))\n",
    "    if not legend:\n",
    "        plt.gca().get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap('seismic')\n",
    "rgba = cmap(0.5)\n",
    "color_brewer_ = numpy.array([cmap(t)[:3] for t in numpy.linspace(0, 1, 16)])\n",
    "common.plot.color_brewer = color_brewer_\n",
    "common.plot.marker_brewer = ['o']*len(common.plot.color_brewer)\n",
    "matplotlib.rcParams['lines.markersize'] = 125\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=[\n",
    "        'at_linf_gd_normalized_lr0007_mom0_i7_e00314_f100',\n",
    "    ],\n",
    "    training_suffixes=[\n",
    "        '_resnet18_rebn_whiten_64',\n",
    "    ],\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_attack_configs = ev.load_input(\n",
    "    config, attack_config_vars=[\n",
    "        [\n",
    "            'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "        ],\n",
    "    ])\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "        ['sequential2_weight_input_l2_random_nonorm2_e05_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "        #['joint_weight_input_l2_gd_nonorm2_lwrl2normalized_lr001_e000075_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "    ])\n",
    "\n",
    "epochs = list(range(5, 150, 10)) + [None]\n",
    "training_labels = ['%s' % epoch for epoch in epochs]\n",
    "input_evaluations = []\n",
    "weight_input_evaluations = []\n",
    "for epoch in epochs:\n",
    "    input_evaluation, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, input_attack_configs, validation=0, train=False, epoch=epoch)\n",
    "    weight_input_evaluation, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, input_weight_attacks_configs, train=False, epoch=epoch)\n",
    "    input_evaluations.append(input_evaluation[0])\n",
    "    weight_input_evaluations.append(weight_input_evaluation[0])\n",
    "    \n",
    "iccv_plot_weight_input_correlation2(\n",
    "    config, [training_configs[0]]*len(epochs), weight_input_evaluations, input_evaluations,\n",
    "    weight_metric='robust_loss', weight_factor=1, weight_statistic='max',\n",
    "    input_metric='robust_loss', input_factor=1, reference_input_metric='robust_loss',\n",
    "    legend_loc='upper left', labels=training_labels,\n",
    "    legend_anchor=(1.05, 1), h=4, w=2, xmin=0, xmax=2,\n",
    "    xlabel='Avg Flatness', legend=False, title=r\"\\textbf{Avg Flatness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Flatness and Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iccv_plot_weight_input_correlation2_methods(\n",
    "    config, training_configs, weight_evaluations, input_evaluations,\n",
    "    weight_metric='robust_test_error',  weight_statistic='max', weight_factor=100,\n",
    "    input_metric='robust_test_error', reference_input_metric='robust_test_error',\n",
    "    input_factor=100, legend_ncol=1, labels=None, legend=True, zero_x=False, groups=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot robust loss and flatness correlation for a set of methods with different hyper-parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert groups is not None\n",
    "    assert len(weight_evaluations) > 0\n",
    "    assert len(weight_evaluations) == len(input_evaluations)\n",
    "    assert len(weight_evaluations[0]) == 1\n",
    "    assert len(input_evaluations[0]) == 1\n",
    "    \n",
    "    x = []\n",
    "    y = [] \n",
    "    c = []\n",
    "    clean_labels = []\n",
    "    \n",
    "    if labels is not None:\n",
    "        set_labels = False \n",
    "    else: \n",
    "        set_labels = True\n",
    "        \n",
    "    c_ = 0\n",
    "    mapping = dict()\n",
    "    line_xs = dict()\n",
    "    line_ys = dict()\n",
    "    for t in range(len(training_configs)):\n",
    "        if weight_evaluations[t][0] is not None and input_evaluations[t][0] is not None:\n",
    "            x_val = round(weight_evaluations[t][0](weight_metric, weight_statistic)[0], 4)*weight_factor -\\\n",
    "                     round(getattr(input_evaluations[t][0], reference_input_metric)(), 4)*input_factor\n",
    "            y_val = round(getattr(input_evaluations[t][0], input_metric)(), 4)*input_factor\n",
    "            x.append(x_val)\n",
    "            y.append(y_val)\n",
    "            \n",
    "            if groups[t] not in line_xs.keys():\n",
    "                line_xs[groups[t]] = []\n",
    "                line_ys[groups[t]] = []\n",
    "            line_xs[groups[t]].append(x_val)\n",
    "            line_ys[groups[t]].append(y_val)\n",
    "            \n",
    "            if labels is None:\n",
    "                clean_labels.append(training_configs[t].directory)\n",
    "                c.append(c_)\n",
    "                c_ += 1\n",
    "            else:\n",
    "                if labels[t] not in mapping.keys():\n",
    "                    c.append(c_)\n",
    "                    mapping[labels[t]] = c_\n",
    "                    c_ += 1\n",
    "                    clean_labels.append(labels[t])\n",
    "                else:\n",
    "                    c.append(mapping[labels[t]])\n",
    "    \n",
    "    x = numpy.array(x)\n",
    "    if zero_x:\n",
    "        x = numpy.maximum(numpy.zeros(x.shape), x)\n",
    "    y = numpy.array(y)\n",
    "    c = numpy.array(c)\n",
    "    \n",
    "    plt.clf()\n",
    "    common.plot.scatter(x, y, c=c, labels=clean_labels,\n",
    "                        s=matplotlib.rcParams['lines.markersize'], **kwargs, ax=plt.gca())\n",
    "    \n",
    "    for i in range(numpy.max(groups) + 1):\n",
    "        res = stats.linregress(line_xs[i], line_ys[i])\n",
    "        \n",
    "        color_i = groups.index(i) + 1\n",
    "        line_x = numpy.array(line_xs[i])\n",
    "        plt.gca().plot(\n",
    "            line_x, res.intercept + res.slope*line_x, color=common.plot.color_brewer[color_i],\n",
    "            marker=None, linewidth=2, linestyle=':', zorder=-1)\n",
    "        \n",
    "    legend_ = plt.gca().legend(\n",
    "        ncol=legend_ncol, loc=kwargs.get('legend_loc', None),\n",
    "        bbox_to_anchor=kwargs.get('legend_anchor', None))\n",
    "    legend_.get_frame().set_alpha(None)\n",
    "    legend_.get_frame().set_facecolor((1, 1, 1, 0.5))\n",
    "    if not legend:\n",
    "        plt.gca().get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 100\n",
    "matplotlib.rcParams['legend.fontsize'] = 12\n",
    "color_brewer_ = numpy.array([\n",
    "    [155, 155, 155],\n",
    "    #\n",
    "    common.plot.darken([31, 120, 180], 1.3),\n",
    "    common.plot.darken([31, 120, 180], 1.15),\n",
    "    [31, 120, 180],\n",
    "    common.plot.lighten([31, 120, 180], 0.85),\n",
    "    common.plot.lighten([31, 120, 180], 0.7),\n",
    "    #\n",
    "    #common.plot.darken([178, 223, 138], 1.3),\n",
    "    common.plot.darken([178, 223, 138], 1.15),\n",
    "    [178, 223, 138],\n",
    "    common.plot.lighten([178, 223, 138], 0.85),\n",
    "    common.plot.lighten([178, 223, 138], 0.7),\n",
    "    #\n",
    "    common.plot.darken([202, 178, 214], 1.15),\n",
    "    [202, 178, 214],\n",
    "    common.plot.lighten([202, 178, 214], 0.85),\n",
    "    common.plot.lighten([202, 178, 214], 0.7),\n",
    "    \n",
    "], dtype=float)\n",
    "color_brewer_ = numpy.minimum(numpy.ones(color_brewer_.shape)*255, color_brewer_)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = [\n",
    "    '.',\n",
    "    #\n",
    "    'o', 'o', 'o', 'o', 'o',\n",
    "    #\n",
    "    'p', 'p', 'p', 'p',\n",
    "    #\n",
    "    '*', '*', '*', '*',\n",
    "]\n",
    "groups = [\n",
    "    -1,\n",
    "    0, 0, 0, 0, 0,\n",
    "    1, 1, 1, 1,\n",
    "    2, 2, 2, 2,\n",
    "]\n",
    "training_config_vars, training_suffixes, training_labels = get_models('corr-method-main', short=False)\n",
    "assert common.plot.color_brewer.shape[0] == len(training_config_vars), common.plot.color_brewer.shape[0]\n",
    "assert len(common.plot.marker_brewer) == len(training_config_vars) , len(common.plot.marker_brewer)\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=training_config_vars,\n",
    "    training_suffixes=training_suffixes,\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "['sequential2_weight_input_l2_random_nonorm2_e05_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "])\n",
    "for i in range(len(input_weight_attacks_configs)):\n",
    "    weight_evaluations, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[i]], train=False)\n",
    "    input_attack_configs = ev.load_input(config, attack_config_vars=[\n",
    "        [\n",
    "            'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "        ],\n",
    "    ])\n",
    "    input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attack_configs[0]], validation=0, train=False)\n",
    "    legend = (i == 0)\n",
    "    \n",
    "    iccv_plot_weight_input_correlation2_methods(\n",
    "        config, training_configs, weight_evaluations, input_evaluations,\n",
    "        weight_metric='robust_loss', weight_factor=1, weight_statistic='mean',\n",
    "        input_metric='robust_loss', reference_input_metric='robust_loss', input_factor=1,\n",
    "        legend_loc='upper left', labels=training_labels, groups=groups,\n",
    "        legend_anchor=(1.01, 1.1), h=5.3, w=5.3,  ymax=4, legend=legend, legend_ncol=1,\n",
    "        xlabel=r\"Average-Case Flatness in RLoss\", ylabel=r\"RLoss (PGD)\",\n",
    "        title=r\"\\textbf{Flatness Across Hyper-Parameters}\")\n",
    "matplotlib.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Loss vs. Average-Case Flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 100\n",
    "color_brewer_ = numpy.array([\n",
    "    [155, 155, 155],\n",
    "    #\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "    [51, 160, 44],\n",
    "    [227, 26, 28],\n",
    "    [253, 191, 111],\n",
    "    [255, 127, 0],\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']\n",
    "common.plot.marker_brewer += ['o']*8\n",
    "\n",
    "training_config_vars1, training_suffixes1, _ = get_models('corr-other')\n",
    "training_config_vars2, training_suffixes2, training_labels2 = get_models('corr')\n",
    "assert common.plot.color_brewer.shape[0] == len(training_config_vars2) + 1, common.plot.color_brewer.shape[0]\n",
    "assert len(common.plot.marker_brewer) == len(training_config_vars2) + 1, len(common.plot.marker_brewer)\n",
    "\n",
    "training_config_vars = training_config_vars1 + training_config_vars2\n",
    "training_suffixes = training_suffixes1 + training_suffixes2\n",
    "training_labels = ['Other']*len(training_config_vars1) + training_labels2\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=training_config_vars,\n",
    "    training_suffixes=training_suffixes,\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "        ['sequential2_weight_input_l2_random_nonorm2_e05_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "    ])\n",
    "for i in range(len(input_weight_attacks_configs)):\n",
    "    weight_evaluations, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[i]], train=False)\n",
    "    input_attack_configs = ev.load_input(\n",
    "        config, attack_config_vars=[\n",
    "            [\n",
    "                'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "            ],\n",
    "        ])\n",
    "    input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attack_configs[0]], validation=0, train=False)\n",
    "    \n",
    "    iccv_plot_weight_input_correlation2(\n",
    "        config, training_configs,  weight_evaluations, input_evaluations,\n",
    "        weight_metric='robust_loss', weight_factor=1, weight_statistic='mean', input_metric='robust_loss',\n",
    "        reference_input_metric='robust_loss', input_factor=1,\n",
    "        legend_loc='upper right', labels=training_labels, legend_anchor=(-0.15, 1.075), h=5.3, w=5.3,\n",
    "        xmin=0, xmax=2.5, legend=True,\n",
    "        xlabel=r\"Average-Case \\textbf{Flatness} in RLoss\", ylabel=r\"RLoss (PGD)\",\n",
    "        title=r\"\\textbf{RLoss vs. Average-Case Flatness in RLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Loss vs. Worst-Case Flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 100\n",
    "color_brewer_ = numpy.array([\n",
    "    [155, 155, 155],\n",
    "    #\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "    [51, 160, 44],\n",
    "    [227, 26, 28],\n",
    "    [253, 191, 111],\n",
    "    [255, 127, 0],\n",
    "\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']\n",
    "common.plot.marker_brewer += ['o']*8\n",
    "\n",
    "training_config_vars1, training_suffixes1, _ = get_models('corr-other')\n",
    "training_config_vars2, training_suffixes2, training_labels2 = get_models('corr')\n",
    "assert common.plot.color_brewer.shape[0] == len(training_config_vars2) + 1, common.plot.color_brewer.shape[0]\n",
    "assert len(common.plot.marker_brewer) == len(training_config_vars2) + 1, len(common.plot.marker_brewer)\n",
    "\n",
    "training_config_vars = training_config_vars1 + training_config_vars2\n",
    "training_suffixes = training_suffixes1 + training_suffixes2\n",
    "training_labels = ['Other']*len(training_config_vars1) + training_labels2\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(\n",
    "    config,\n",
    "    training_config_vars=training_config_vars,\n",
    "    training_suffixes=training_suffixes,\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "        ['joint_weight_input_l2_gd_nonorm2_lwrl2normalized_lr001_e000075_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "    ])\n",
    "for i in range(len(input_weight_attacks_configs)):\n",
    "    weight_evaluations, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[i]], train=False)\n",
    "    input_attack_configs = ev.load_input(\n",
    "        config, attack_config_vars=[\n",
    "            [\n",
    "                'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "            ],\n",
    "            [\n",
    "                'input_linf_aa_standard_e00314',\n",
    "            ],\n",
    "        ])\n",
    "    input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attack_configs[0]], validation=0, train=False)\n",
    "    \n",
    "    iccv_plot_weight_input_correlation2(\n",
    "        config, training_configs, weight_evaluations, input_evaluations,\n",
    "        weight_metric='robust_loss', weight_factor=1, weight_statistic='max', input_metric='robust_loss',\n",
    "        reference_input_metric='robust_loss', input_factor=1,\n",
    "        legend_loc='upper right', labels=training_labels,\n",
    "        legend_anchor=(-0.15, 1.075), h=5.3, w=5.3, xmin=0, xmax=0.5,\n",
    "        xlabel=r\"Worst-Case \\textbf{Flatness} in RLoss\", ylabel=r\"RLoss (PGD)\",\n",
    "        legend=True, title=r\"\\textbf{RLoss vs. \\emph{Worst}-Case Flatness in RLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Generalization Gap vs. Average-Case Flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, y, c=None, labels=None, use_labels=None, ax=plt.gca(), **kwargs):\n",
    "    \"\"\"\n",
    "    Scatter plot or 2D data.\n",
    "\n",
    "    :param x: x data\n",
    "    :type x: numpy.ndarray\n",
    "    :param y: y data\n",
    "    :type y: numpy.ndarray\n",
    "    :param c: labels as N x 1\n",
    "    :type c: numpy.ndarray\n",
    "    :param labels: label names\n",
    "    :type labels: [str]\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == len(y.shape), 'only one dimensional data arrays supported'\n",
    "    assert x.shape[0] == y.shape[0], 'only two-dimensional data can be scatter-plotted'\n",
    "    assert c is None or x.shape[0] == c.shape[0], 'data and labels need to have same number of rows'\n",
    "    if c is not None:\n",
    "        assert labels is not None, 'if classes are given, labels need also to be given'\n",
    "\n",
    "    if c is not None:\n",
    "        if len(c.shape) > 1:\n",
    "            c = numpy.squeeze(c)\n",
    "    elif c is None:\n",
    "        c = numpy.zeros((x.shape[0]))\n",
    "        labels = [0]\n",
    "    c = c.astype(int)  # Important for indexing\n",
    "\n",
    "    if use_labels is None:\n",
    "        use_labels = [False]*c.shape[0]\n",
    "    \n",
    "    unique_labels = numpy.unique(c)\n",
    "    assert unique_labels.shape[0] <= len(common.plot.color_brewer), 'currently a maxmimum of 12 different labels are supported'\n",
    "    # assert unique_labels.shape[0] == len(labels), 'labels do not match given classes'\n",
    "    assert numpy.min(unique_labels) >= 0 and numpy.max(unique_labels) < len(labels), 'classes contain elements not in labels'\n",
    "\n",
    "    for i in range(unique_labels.shape[0]):\n",
    "        marker = kwargs.get('marker', common.plot.marker_brewer[i])\n",
    "        label = label=labels[unique_labels[i]] if use_labels[i] else None\n",
    "        ax.scatter(x[c == unique_labels[i]], y[c == unique_labels[i]],\n",
    "                       c=numpy.repeat(numpy.expand_dims(common.plot.color_brewer[i], 0), x[c == unique_labels[i]].shape[0], axis=0),\n",
    "                       marker=marker, s=kwargs.get('s', 45),\n",
    "                       edgecolor='black', linewidth=kwargs.get('linewidth', 0.5), label=label)\n",
    "    has_colors = (c is not None)\n",
    "    common.plot.label(ax, legend=has_colors, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iccv_plot_weight_input_diff_correlation2(\n",
    "    config, training_configs, weight_evaluations, input_evaluations_a, input_evaluations_b,\n",
    "    weight_metric='robust_test_error', reference_input_metric='robust_test_error', \n",
    "    weight_statistic='max', weight_factor=100, labels=None, input_metric='robust_test_error',\n",
    "    input_factor=100, min_zero=False, legend_ncol=1, legend=True, use_labels=None, regression=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot robust loss difference against flatness.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(weight_evaluations) > 0\n",
    "    assert len(weight_evaluations) == len(input_evaluations_a)\n",
    "    assert len(weight_evaluations) == len(input_evaluations_b)\n",
    "    assert len(weight_evaluations[0]) == 1\n",
    "    assert len(input_evaluations_a[0]) == 1\n",
    "    assert len(input_evaluations_b[0]) == 1\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    c = []\n",
    "    clean_labels = []\n",
    "    \n",
    "    if labels is not None:\n",
    "        set_labels = False \n",
    "    else:\n",
    "        labels = []\n",
    "        set_labels = True\n",
    "        \n",
    "    c_ = 0\n",
    "    mapping = dict()\n",
    "    for t in range(len(training_configs)):\n",
    "        if weight_evaluations[t][0] is not None and input_evaluations_a[t][0] is not None and input_evaluations_b[t][0] is not None: \n",
    "            flatness = round(weight_evaluations[t][0](weight_metric, weight_statistic)[0], 4)*weight_factor -\\\n",
    "                     round(getattr(input_evaluations_a[t][0], reference_input_metric)(), 4)*input_factor\n",
    "            if min_zero:\n",
    "                flatness = max(0, flatness)\n",
    "            x.append(flatness)\n",
    "            y.append(round(getattr(input_evaluations_a[t][0], input_metric)(), 4)*input_factor -\n",
    "                     round(getattr(input_evaluations_b[t][0], input_metric)(), 4)*input_factor)\n",
    "            \n",
    "            if labels is None:\n",
    "                clean_labels.append(training_configs[t].directory)\n",
    "                c.append(c_)\n",
    "                c_ += 1\n",
    "            else:\n",
    "                if labels[t] not in mapping.keys():\n",
    "                    c.append(c_)\n",
    "                    mapping[labels[t]] = c_\n",
    "                    c_ += 1\n",
    "                    clean_labels.append(labels[t])\n",
    "                else:\n",
    "                    c.append(mapping[labels[t]])\n",
    "    \n",
    "    x = numpy.array(x)\n",
    "    y = numpy.array(y)\n",
    "    c = numpy.array(c)\n",
    "    \n",
    "    plt.clf()\n",
    "    if regression:\n",
    "        res = stats.linregress(x, y)\n",
    "        xs1 = numpy.array([numpy.min(x), numpy.max(x)])\n",
    "        plt.gca().plot(\n",
    "            xs1, res.intercept + res.slope*xs1, color='red', marker=None, linewidth=3, linestyle=':')\n",
    "        \n",
    "    scatter(\n",
    "        x, y, c=c, labels=clean_labels, use_labels=use_labels,\n",
    "        s=matplotlib.rcParams['lines.markersize'], **kwargs, ax=plt.gca())\n",
    "    legend_ = plt.gca().legend(\n",
    "        ncol=legend_ncol, loc=kwargs.get('legend_loc', None),\n",
    "        bbox_to_anchor=kwargs.get('legend_anchor', None))\n",
    "    legend_.get_frame().set_alpha(None)\n",
    "    legend_.get_frame().set_facecolor((1, 1, 1, 0.5))\n",
    "    if not legend:\n",
    "        plt.gca().get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['lines.markersize'] = 100\n",
    "color_brewer_ = numpy.array([\n",
    "    [155, 155, 155],\n",
    "    #\n",
    "    [166, 206, 227],\n",
    "    [31, 120, 180],\n",
    "    [251, 154, 153],\n",
    "    [178, 223, 138],\n",
    "    [51, 160, 44],\n",
    "    [227, 26, 28],\n",
    "    [253, 191, 111],\n",
    "    [255, 127, 0],\n",
    "\n",
    "], dtype=float)\n",
    "common.plot.color_brewer = color_brewer_/255.\n",
    "common.plot.marker_brewer = ['.']\n",
    "common.plot.marker_brewer += ['o']*8\n",
    "\n",
    "training_config_vars1, training_suffixes1, _ = get_models('corr-other')\n",
    "training_config_vars2, training_suffixes2, training_labels2 = get_models('corr')\n",
    "assert common.plot.color_brewer.shape[0] == len(training_config_vars2) + 1, common.plot.color_brewer.shape[0]\n",
    "assert len(common.plot.marker_brewer) == len(training_config_vars2) + 1, len(common.plot.marker_brewer)\n",
    "\n",
    "training_config_vars = training_config_vars1 + training_config_vars2\n",
    "training_suffixes = training_suffixes1 + training_suffixes2\n",
    "training_labels = ['Other']*len(training_config_vars1) + training_labels2\n",
    "\n",
    "training_configs, weight_attack_configs = ev.load(config,\n",
    "    training_config_vars=training_config_vars,\n",
    "    training_suffixes=training_suffixes,\n",
    "    attack_config_vars=[],\n",
    ")\n",
    "input_weight_attacks_configs = ev.load_weight_input(\n",
    "    config, attack_config_vars=[\n",
    "        ['sequential2_weight_input_l2_random_nonorm2_e05_linf_gd_normalized_lr0007_e00314_i20_at10_test'],\n",
    "    ])\n",
    "for i in range(len(input_weight_attacks_configs)):\n",
    "    weight_evaluations, _ = ev.get_weight_input_attack_evaluations(\n",
    "        config, training_configs, [input_weight_attacks_configs[i]], train=False)\n",
    "    input_attacks_configs = ev.load_input(\n",
    "        config, attack_config_vars=[\n",
    "            [\n",
    "                'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10',\n",
    "            ],\n",
    "            [\n",
    "                'input_linf_gd_normalized_lr0007_mom0_i20_e00314_at10_train',\n",
    "            ],\n",
    "        ])\n",
    "    \n",
    "    test_input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attacks_configs[0]], validation=0, train=False)\n",
    "    train_input_evaluations, _ = ev.get_input_attack_evaluations(\n",
    "        config, training_configs, [input_attacks_configs[1]], validation=0, train=True)\n",
    "    \n",
    "    iccv_plot_weight_input_diff_correlation2(\n",
    "        config, training_configs, weight_evaluations, test_input_evaluations, train_input_evaluations,\n",
    "        weight_metric='robust_loss', input_metric='robust_loss', reference_input_metric='robust_loss',\n",
    "        weight_factor=1, weight_statistic='mean', input_factor=1,\n",
    "        legend_loc='lower right', labels=training_labels, legend_anchor=(1, 0), h=5.3, w=5.3,\n",
    "        xmin=0, xmax=2.5, legend=True,\n",
    "        xlabel=r\"Average-Case Flatness in RLoss\", ylabel='Test $-$ Train RLoss (PGD)',\n",
    "        title=r\"\\textbf{\\emph{Test $-$ Train} RLoss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "729px",
    "left": "29px",
    "top": "108.967px",
    "width": "330.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
